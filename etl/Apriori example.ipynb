{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3088b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import time\n",
    "import psycopg2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    " \n",
    "\n",
    "def connect_postgres():\n",
    "    database = os.environ['POSTGRES_DB']\n",
    "    user = os.environ['POSTGRES_USER']\n",
    "    password = os.environ['POSTGRES_PASSWORD']\n",
    "    host = os.environ['POSTGRES_SERVER']\n",
    "    port = 5432\n",
    "\n",
    "    exc, conn, engine = None, None, None\n",
    "\n",
    "    for _ in range(5):\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                database=database, user=user, password=password, host=host, port=port)\n",
    "        except Exception as e:\n",
    "            logging.warning(\"Error connecting to postgres, will retry in 3 sec: %s\", e)\n",
    "            time.sleep(3)\n",
    "            exc = e\n",
    "        else:\n",
    "            logging.info(\"Connected...\")\n",
    "            logging.info(\"Everything goes well from Postgres, you're a fu*** pro...\")\n",
    "            \n",
    "            engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "                user, password, host, port, database\n",
    "            ))\n",
    "            break\n",
    "    else:\n",
    "        logging.error(\"Unable to connect to  %s DB\", database)\n",
    "        raise exc\n",
    "    \n",
    "    return [conn, engine]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fdf34586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Connected...\n",
      "INFO:root:Everything goes well from Postgres, you're a fu*** pro...\n"
     ]
    }
   ],
   "source": [
    "[conn, engine] = connect_postgres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b3f2500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app/.venv/lib/python3.8/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_sql(\"\"\"\n",
    "    SELECT code, trans_date_id as date, copy.id as books\n",
    "    FROM public.copytransaction, public.copy, public.student, public.title, public.transactiontype\n",
    "    WHERE \n",
    "        trans_borrower_code = student.id and\n",
    "        trans_copy_code_id = copy.id and \n",
    "        trans_tittle_code_id = title.id and \n",
    "        trans_type_id = transactiontype.id and \n",
    "        trans_location_code_id = 5 and \n",
    "        trans_type_code IN ('ISS', 'REN', 'NON', 'PLOAN')\n",
    "    GROUP BY code, trans_date_id, copy.id\n",
    "\"\"\", con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "67193990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>books</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>198224610</td>\n",
       "      <td>20000928</td>\n",
       "      <td>547476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198224610</td>\n",
       "      <td>20000928</td>\n",
       "      <td>547477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>198224610</td>\n",
       "      <td>20001014</td>\n",
       "      <td>547477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198224610</td>\n",
       "      <td>20001117</td>\n",
       "      <td>17499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198224610</td>\n",
       "      <td>20001120</td>\n",
       "      <td>172235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352753</th>\n",
       "      <td>201880023</td>\n",
       "      <td>20180305</td>\n",
       "      <td>831823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352754</th>\n",
       "      <td>201880026</td>\n",
       "      <td>20180305</td>\n",
       "      <td>832497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352755</th>\n",
       "      <td>201880026</td>\n",
       "      <td>20180307</td>\n",
       "      <td>823259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352756</th>\n",
       "      <td>201880026</td>\n",
       "      <td>20180313</td>\n",
       "      <td>834960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352757</th>\n",
       "      <td>201880026</td>\n",
       "      <td>20180320</td>\n",
       "      <td>834962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3352758 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              code      date   books\n",
       "0        198224610  20000928  547476\n",
       "1        198224610  20000928  547477\n",
       "2        198224610  20001014  547477\n",
       "3        198224610  20001117   17499\n",
       "4        198224610  20001120  172235\n",
       "...            ...       ...     ...\n",
       "3352753  201880023  20180305  831823\n",
       "3352754  201880026  20180305  832497\n",
       "3352755  201880026  20180307  823259\n",
       "3352756  201880026  20180313  834960\n",
       "3352757  201880026  20180320  834962\n",
       "\n",
       "[3352758 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a2e3d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3352758 entries, 0 to 3352757\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   code    int32\n",
      " 1   date    int32\n",
      " 2   books   int32\n",
      "dtypes: int32(3)\n",
      "memory usage: 38.4 MB\n"
     ]
    }
   ],
   "source": [
    "df = df.astype({col: 'int32' for col in df.select_dtypes('int64').columns})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc1afd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code     0\n",
       "date     0\n",
       "books    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exploring the data\n",
    "\n",
    "# checking null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a9a64643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "chunk_max_size = 100000\n",
    "chunks = int(math.ceil(len(df) / chunk_max_size))\n",
    "\n",
    "rules = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1cb04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules identified:  3366\n",
      "Rules identified:  3043\n",
      "Rules identified:  14865\n",
      "Rules identified:  94443\n",
      "Rules identified:  3340\n",
      "Rules identified:  20738\n",
      "Rules identified:  10329\n",
      "Rules identified:  12565\n",
      "Rules identified:  30854\n",
      "Rules identified:  8278\n",
      "Rules identified:  36041\n",
      "Rules identified:  4905\n",
      "Rules identified:  2235\n",
      "Rules identified:  6942\n",
      "Rules identified:  2017\n",
      "Rules identified:  6483\n",
      "Rules identified:  3028\n",
      "Rules identified:  2916\n",
      "Rules identified:  1721\n",
      "Rules identified:  1657\n"
     ]
    }
   ],
   "source": [
    "for df_chunk in np.array_split(df, chunks):\n",
    "    df_chunk.books = df_chunk.books.transform(lambda x: [x])    \n",
    "    library = df_chunk.groupby(['code','date']).sum()['books'].reset_index(drop=True)\n",
    "    transform_library = encoder.fit(library).transform(library)\n",
    "    transactions = pd.DataFrame(transform_library, columns=encoder.columns_)\n",
    "    \n",
    "    # TODO: understand this very well\n",
    "    frequent_itemsets = fpgrowth(transactions, min_support=10/len(df_chunk), use_colnames=True)\n",
    "    if not frequent_itemsets.empty:\n",
    "        # rule = association_rules(frequent_itemsets, metric=\"confidence\",  min_threshold=0.5)\n",
    "        rule = association_rules(frequent_itemsets)\n",
    "        \n",
    "        if not rule.empty:\n",
    "            rule[\"antecedent_len\"] = rule[\"antecedents\"].apply(lambda x: len(x))\n",
    "            association_rule = rule[\n",
    "                (rule['antecedent_len'] >= 2) &\n",
    "                (rule['confidence'] >= 0.5) &\n",
    "                (rule['lift'] >= 1)\n",
    "            ]\n",
    "            \n",
    "            rules.append(association_rule)\n",
    "            print(\"Rules identified: \", len(rule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dd6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(rules).reset_index(drop=True)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save association rules to a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3064cf68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
